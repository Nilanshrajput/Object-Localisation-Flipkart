{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import Conv2D, Reshape\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.backend import epsilon\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.35\n",
    "\n",
    "# 96, 128, 160, 192, 224\n",
    "IMAGE_SIZE = 160\n",
    "EPOCHS = 7\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 50\n",
    "MULTI_PROCESSING = True\n",
    "THREADS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_CSV = \"C:/Users/itsab/Downloads/training_try_2.csv\"  #img_dir='drive/inter_iit/conv_data/sat_match2'\n",
    "VALIDATION_CSV = \"C:/Users/itsab/Downloads/validation_try_1.csv\"\n",
    "path2=\"C:/Users/itsab/Desktop/Flipkart/images/\"\n",
    "model_path=\"C:/Users/itsab/Desktop/Flipkart/model_try_7.hd5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.paths = []\n",
    "        \n",
    "        with open(csv_file, \"r\") as file:\n",
    "            self.coords = np.zeros((sum(1 for line in file), 4))\n",
    "            print(self.coords.shape)\n",
    "            file.seek(0)\n",
    "\n",
    "            reader = csv.reader(file, delimiter=\",\")\n",
    "            real_index=0;\n",
    "            for index, row in enumerate(reader):\n",
    "                #for i, r in enumerate(row[1:5]):\n",
    "                    #row[i+1] = int(r)\n",
    "              if not index==0: \n",
    "                try:    \n",
    "                  path=row[0];\n",
    "\n",
    "                  path=path2+path;\n",
    "                  filename=path\n",
    "                  im = Image.open(filename)\n",
    "                  im.verify() \n",
    "                  im.close() \n",
    "                  im = Image.open(filename) \n",
    "                  im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "                  im.close()\n",
    "                  im= Image.open(filename)\n",
    "                  im.load()\n",
    "\n",
    "                  if index%500==0:\n",
    "                    print (index)\n",
    "                  x0=int(row[1]);\n",
    "                  x1=int(row[2]);\n",
    "                  y0=int(row[3])\n",
    "                  y1=int(row[4]);\n",
    "                  #path=path2+path;\n",
    "                 # path,x0, y0, x1, y1, _, _ = row\n",
    "                 # print(index)\n",
    "                  img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "                  image_height=int(img.shape[0])\n",
    "                  image_width=int(img.shape[1])\n",
    "                  self.coords[real_index, 0] = x0 * IMAGE_SIZE / image_width\n",
    "                  self.coords[real_index, 1] = y0 * IMAGE_SIZE / image_height\n",
    "                  self.coords[real_index, 2] = (x1 - x0) * IMAGE_SIZE / image_width\n",
    "                  self.coords[real_index, 3] = (y1 - y0) * IMAGE_SIZE / image_height \n",
    "\n",
    "                  self.paths.append(path)\n",
    "                  real_index+=1;\n",
    "                except:\n",
    "                  print (path)\n",
    "                  \n",
    "                  continue\n",
    "        print(len(self.paths))   \n",
    "        print (real_index)     \n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.paths) / BATCH_SIZE)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.paths[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
    "        batch_coords = self.coords[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
    "\n",
    "        batch_images = np.zeros((len(batch_paths), IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32)\n",
    "        for i, f in enumerate(batch_paths):\n",
    "            img = Image.open(f)\n",
    "            img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "            batch_images[i] = preprocess_input(np.array(img, dtype=np.float32))\n",
    "            img.close()\n",
    "\n",
    "        return batch_images, batch_coords"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_csv=pd.read_csv('C:/Users/itsab/Downloads/training_try_2.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_csv=pd.read_csv('C:/Users/itsab/Downloads/training_try_2.csv')\n",
    "\n",
    "labels=train_csv.set_index('image_name').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=train_csv['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pat_tr=list(pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def preprocess_image(img):\n",
    "  w,h = 224, 224 \n",
    "  \n",
    "  img = cv2.resize(img, (w,h))\n",
    "  img = img/255. \n",
    "  \n",
    "  return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from random import shuffle\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "base=Path('images')\n",
    "\n",
    "\n",
    "\n",
    "shuffle(pat_tr)\n",
    "\n",
    "def image_generator(input_ids, batch_size = 32):\n",
    "  \n",
    "  while True:\n",
    "    batch_paths = np.random.choice(a= input_ids, size = batch_size)\n",
    "    \n",
    "    batch_input = []\n",
    "    batch_output = []\n",
    "    \n",
    "    for input_id in batch_paths:\n",
    "      input = cv2.imread(join(base, input_id))\n",
    "      output = labels[input_id]\n",
    "      \n",
    "      input = preprocess_image(input)\n",
    "      \n",
    "      batch_input += [input]\n",
    "      batch_output += [output]\n",
    "   \n",
    "    batch_x = np.array(batch_input)\n",
    "    batch_y = np.array(batch_output)\n",
    "    \n",
    "    yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=image_generator(pat_tr,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n",
      "(64, 4)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(train_gen)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation(Callback):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        mse = 0\n",
    "        intersections = 0\n",
    "        unions = 0\n",
    "\n",
    "        for i in range(len(self.generator)):\n",
    "            batch_images, gt = self.generator[i]\n",
    "            pred = self.model.predict_on_batch(batch_images)\n",
    "            mse += np.linalg.norm(gt - pred, ord='fro') / pred.shape[0]\n",
    "\n",
    "            pred = np.maximum(pred, 0)\n",
    "\n",
    "            diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n",
    "            diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n",
    "            intersection = np.maximum(diff_width, 0) * np.maximum(diff_height, 0)\n",
    "\n",
    "            area_gt = gt[:,2] * gt[:,3]\n",
    "            area_pred = pred[:,2] * pred[:,3]\n",
    "            union = np.maximum(area_gt + area_pred - intersection, 0)\n",
    "\n",
    "            intersections += np.sum(intersection * (union > 0))\n",
    "            unions += np.sum(union)\n",
    "\n",
    "        iou = np.round(intersections / (unions + epsilon()), 4)\n",
    "        logs[\"val_iou\"] = iou\n",
    "\n",
    "        mse = np.round(mse, 4)\n",
    "        logs[\"val_mse\"] = mse\n",
    "\n",
    "        print(\" - val_iou: {} - val_mse: {}\".format(iou, mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(trainable=False):\n",
    "    #model = MobileNetV2()\n",
    "    model = InceptionV3(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
    "    # to freeze layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    x = model.layers[-1].output\n",
    "    x = Conv2D(4, kernel_size=3, name=\"coords\")(x)\n",
    "    x = Reshape((4,))(x)\n",
    "\n",
    "    return Model(inputs=model.input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\itsab\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Checkpointable._track_checkpointable() passed type <class 'keras.engine.input_layer.InputLayer'>, not a Checkpointable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-834f03506210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-8762f3fb83f6>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(trainable)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\itsab\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;31m# Create a cache for iterator get_next op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_get_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeakKeyDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\itsab\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     80\u001b[0m       \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m       \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\itsab\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m       \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\itsab\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers_by_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers_by_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_track_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;31m# Create the node linking internal inputs to internal outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\itsab\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_track_layers\u001b[1;34m(self, layers)\u001b[0m\n\u001b[0;32m    325\u001b[0m       \u001b[1;31m# case it has/will have Checkpointable dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m       self._track_checkpointable(\n\u001b[1;32m--> 327\u001b[1;33m           layer, name='layer-%d' % layer_index, overwrite=True)\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\itsab\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_track_checkpointable\u001b[1;34m(self, checkpointable, name, overwrite)\u001b[0m\n\u001b[0;32m    686\u001b[0m       raise TypeError(\n\u001b[0;32m    687\u001b[0m           (\"Checkpointable._track_checkpointable() passed type %s, not a \"\n\u001b[1;32m--> 688\u001b[1;33m            \"Checkpointable.\") % (type(checkpointable),))\n\u001b[0m\u001b[0;32m    689\u001b[0m     \u001b[0mnew_reference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCheckpointableReference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpointable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[0mcurrent_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Checkpointable._track_checkpointable() passed type <class 'keras.engine.input_layer.InputLayer'>, not a Checkpointable."
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = DataGenerator(TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = Validation(generator=DataGenerator(VALIDATION_CSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[])\n",
    "checkpoint = ModelCheckpoint(\"model-{val_iou:.2f}.h5\", monitor=\"val_iou\", verbose=1, save_best_only=True,\n",
    "                               save_weights_only=True, mode=\"max\", period=1)\n",
    "stop = EarlyStopping(monitor=\"val_iou\", patience=PATIENCE, mode=\"max\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_iou\", factor=0.2, patience=10, min_lr=1e-7, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "len(train_datagen)\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit_generator(generator=train_gen,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=[cp],\n",
    "                      workers=THREADS,\n",
    "                      use_multiprocessing=False,\n",
    "                      shuffle=False,steps_per_epoch=None,\n",
    "                      verbose=1)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_datagen,\n",
    "                      epochs=10,\n",
    "                      callbacks=[cp],\n",
    "                      workers=THREADS,\n",
    "                      use_multiprocessing=False,\n",
    "                      shuffle=False,steps_per_epoch=None,\n",
    "                      verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_2=\"C:/Users/itsab/Desktop/Flipkart/model_try_2.hd5\"\n",
    "model.save(model_path_2)\n",
    "model_path_2=\"C:/Users/itsab/Desktop/Flipkart/model_try_4.hd5\"\n",
    "model.fit_generator(generator=train_datagen,\n",
    "                      epochs=20,\n",
    "                      callbacks=[cp],\n",
    "                      workers=THREADS,\n",
    "                      use_multiprocessing=False,\n",
    "                      shuffle=True,steps_per_epoch=None,\n",
    "                      verbose=1)\n",
    "model.save(model_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
